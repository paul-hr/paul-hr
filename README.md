<h1>Hi <img src="https://github.com/TheDudeThatCode/TheDudeThatCode/blob/master/Assets/Hi.gif" width="38px">, I'm Paul Huaroc </h1>

I'm a Data Engineer specializing in building scalable data pipelines, ETL processes, and cloud-based analytics solutions. With hands-on experience in processing large-scale datasets, automating workflows with Python, and leveraging tools like AWS, Azure, and Databricks, I focus on delivering secure, efficient, and business-value-driven data architectures.

---
## Featured Projects

* **ETL Pipeline for CRM Migration**  
  Developed a PySpark and SQL-based ETL process to migrate historical data into Zoho CRM, reducing manual processing by 55-65%. Included web scraping automation for data extraction, cutting load times by 70%. (Repository: [etl-crm-migration](https://github.com/paulhuarocr/etl-crm-migration))

* **Automated Economic Data Scraping & Reporting**  
  Built Python web scraping scripts with Polars and Pandas for collecting data from economic, employment, real estate, and tourism portals. Automated daily reports via Jupyter Notebooks to Microsoft Teams, ensuring clean integration into macro-economic databases. Enhanced with data validation for high-volume updates. (Repository: [economic-data-pipeline](https://github.com/paulhuarocr/economic-data-pipeline))

* **AWS Glue ETL Optimization**  
  Migrated ETL scripts from library-dependent to native Spark for improved efficiency in AWS Glue. Orchestrated pipelines using Step Functions and supported Power BI dashboard enhancements for client requirements. (Repository: [aws-etl-optimizer](https://github.com/paulhuarocr/aws-etl-optimizer))

* **Event Analytics Data Warehouse**  
  Designed database structures and processed large volumes of data for analyzing participation in fairs, congresses, and campaigns. Generated automated KPI reports in Power BI and Python for commercial insights. (Repository: [event-analytics-warehouse](https://github.com/paulhuarocr/event-analytics-warehouse))
  
---
## Tech Stack

* **ETL & Big Data**: PySpark, Pandas, Polars, Web Scraping (BeautifulSoup/Selenium), SQL/PLSQL, Parquet, Databricks
* **Cloud & DevOps**: AWS (Glue, S3, Step Functions, Lightsail), Microsoft Fabric, Azure (DevOps, Fundamentals), Git, GitHub, Jenkins
* **Databases & Storage**: Relational Databases (SQL-based), Data Lakes, CRM Integration (Zoho)
* **Visualization & Reporting**: Power BI, Matplotlib, Excel, Bash Scripting, Jupyter Notebooks
* **Languages & Tools**: Python (Advanced), Scala, API Development, Automation Frameworks
---
## Certifications

* Academy Accreditation - Databricks Lakehouse Fundamentals
* AZ-900: Microsoft Azure Fundamentals 
* DP-700: Fabric Data Engineer Associate (In Progress)
---
## About Me

Top performer in UNMSM (Tercio Superior 2023, Quinto Superior 2020) with intermediate English skills. Strong in teamwork, problem-solving, adaptability, proactivity, and flexibility. Always eager to tackle complex data challenges and contribute to open-source projects in data engineering.

Let's connect if you're building robust data infrastructures, optimizing ETL workflows, or exploring big data innovations!  
ðŸ“« Reach me at: paul.huaroc.r@gmail.com | LinkedIn: [paulhuarocr](https://linkedin.com/in/paulhuarocr) | Phone: +51 919033801
